<html>

  <p>This is a demo for <a href="https://htmlday.com/2025">html day 2025</a> which attempts to read html from a device camera and render it on the web.</p>

  <div id="log"></div>
  
  <!-- Camera video element -->
  <div id="camera-container">
    <button id="start-camera">Start Camera</button>
    <button id="stop-camera">Stop Camera</button>
    <button id="ocr-camera">Camera new OCR Frame</button>
    <br />
    <video id="camera-video" autoplay playsinline muted height="25%"></video>
    <div id="captured-frame-container">
      <h3>Last Captured Frame:</h3>
      <canvas id="captured-frame" style="border: 2px solid #ccc; max-width: 100%; height: 25%;"></canvas>
    </div>
  </div>
  
  <img height="300px" id="htmlhandwritten" src="knocknoc2.jpg">
  <p>image credit <a href="https://www.johncarr.online/knock-knock-jokes/">johncarr.online/knock-knock-jokes</a></p>

  <p>Code is at<a href="https://github.com/here/html-day-render-handwriting">github/here/html-day-render-handwriting</a></p>
  <p>Start local server with `python3 -m http.server` and view at http://127.0.0.1:8000/</p>
  <p>It uses <a href="https://github.com/naptha/tesseract.js">tesseract.js</a> to perform OCR on the camera frame.</p>
  <p>It uses <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaDevices/getUserMedia">getUserMedia</a> to access the camera.</p>
  <p>It uses <a href="https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API">Canvas API</a> to draw the camera frame and the OCR result.</p>
  <p>It uses <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API">WebRTC API</a> to access the camera.</p>
  <p>It uses <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API">WebRTC API</a> to access the camera.</p>

  <!--  <img src="https://herebox.org/wp-content/uploads/2025/07/the-triplets-of-belleville-749x1024.jpg"> -->
 
    <script type="module">
        import tesseractJs from "https://esm.sh/tesseract.js@6.0.1";

        // Get the image and log elements from the DOM
        const imageElement = document.getElementById('htmlhandwritten');
        const logElement = document.getElementById('log');
        
        // Function to update the log/status on the page
        function updateLog(status) {
          logElement.innerHTML = `<p>${status}</p>`;
          console.log(status);
        }
        
        // The main OCR function
        async function performOCR() {
          updateLog('Recognizing text... This may take a moment.');
        
          try {
            // Recognize text from the image element
            const result = await tesseractJs.recognize(
              imageElement,
              'eng', // Language code (e.g., 'eng' for English)
              {
                logger: m => {
                  // Log progress to the console and update the UI
                  const progressStatus = `${m.status} (${(m.progress * 100).toFixed(2)}%)`;
                  updateLog(progressStatus);
                }
              }
            );
            
            // Debug: Log the full result structure
            console.log('Full OCR result:', result);
            
            const { data: { text, words } } = result;
        
            // Display the full extracted text
            updateLog('Recognition Complete!');
            logElement.innerHTML += `<h2>Full Text:</h2><pre>${text}</pre>`;
        
            // Display individual words and their confidence levels (if available)
            if (words && Array.isArray(words)) {
              logElement.innerHTML += '<h2>Individual Words:</h2>';
              const wordList = words.map(w => `<li>${w.text} (Confidence: ${w.confidence.toFixed(2)}%)</li>`).join('');
              logElement.innerHTML += `<ul>${wordList}</ul>`;
            } else {
              logElement.innerHTML += '<p><em>Word-level data not available</em></p>';
            }
        
          } catch (error) {
            console.error('OCR failed:', error);
            updateLog('Failed to recognize text. See console for details.');
          }
        }
        
        // Run the OCR function when the image has loaded
        imageElement.onload = () => {
          performOCR();
        };
        
        // If the image is already cached/loaded, run it immediately
        if (imageElement.complete) {
          performOCR();
        }
        
        // Camera functionality
        const videoElement = document.getElementById('camera-video');
        const startButton = document.getElementById('start-camera');
        const stopButton = document.getElementById('stop-camera');
        const ocrButton = document.getElementById('ocr-camera');
        let stream = null;
        
        // Start camera function
        async function startCamera() {
          try {
            updateLog('Requesting camera permissions...');
            
            // Request camera access with specific constraints for mobile
            stream = await navigator.mediaDevices.getUserMedia({
              video: {
                facingMode: 'environment', // Use back camera on mobile
                width: { ideal: 1280 },
                height: { ideal: 720 }
              },
              audio: false
            });
            
            // Set the video source
            videoElement.srcObject = stream;
            
            updateLog('Camera started successfully!');
            startButton.style.display = 'none';
            stopButton.style.display = 'inline-block';
            
          } catch (error) {
            console.error('Camera access failed:', error);
            updateLog(`Camera access failed: ${error.message}`);
          }
        }
        
        // Stop camera function
        function stopCamera() {
          if (stream) {
            stream.getTracks().forEach(track => track.stop());
            stream = null;
            videoElement.srcObject = null;
            updateLog('Camera stopped');
            startButton.style.display = 'inline-block';
            stopButton.style.display = 'none';
          }
        }
        
        // OCR function for camera video frame
        async function performOCROnCamera() {
          if (!stream || !videoElement.srcObject) {
            updateLog('Please start the camera first');
            return;
          }
          
          updateLog('Performing OCR on camera frame...');
          
          try {
            // Get the display canvas for showing the captured frame
            const displayCanvas = document.getElementById('captured-frame');
            const displayCtx = displayCanvas.getContext('2d');
            
            // Set display canvas size to match video dimensions
            displayCanvas.width = videoElement.videoWidth;
            displayCanvas.height = videoElement.videoHeight;
            
            // Draw the current video frame to the display canvas
            displayCtx.drawImage(videoElement, 0, 0, displayCanvas.width, displayCanvas.height);
            
            // Create a temporary canvas for OCR processing
            const canvas = document.createElement('canvas');
            const ctx = canvas.getContext('2d');
            
            // Set canvas size to match video dimensions
            canvas.width = videoElement.videoWidth;
            canvas.height = videoElement.videoHeight;
            
            // Draw the current video frame to the canvas
            ctx.drawImage(videoElement, 0, 0, canvas.width, canvas.height);
            
            // Perform OCR on the canvas
            const result = await tesseractJs.recognize(
              canvas,
              'eng',
              {
                logger: m => {
                  const progressStatus = `Camera OCR: ${m.status} (${(m.progress * 100).toFixed(2)}%)`;
                  updateLog(progressStatus);
                }
              }
            );
            
            // Debug: Log the full result structure
            console.log('Camera OCR result:', result);
            
            const { data: { text, words } } = result;
            
            // Display the results
            updateLog('Camera OCR Complete!');
            logElement.innerHTML += `<h2>Camera Frame Text:</h2><pre>${text}</pre>`;
            
            // Display individual words and their confidence levels (if available)
            if (words && Array.isArray(words)) {
              logElement.innerHTML += '<h2>Camera Frame Words:</h2>';
              const wordList = words.map(w => `<li>${w.text} (Confidence: ${w.confidence.toFixed(2)}%)</li>`).join('');
              logElement.innerHTML += `<ul>${wordList}</ul>`;
            } else {
              logElement.innerHTML += '<p><em>Word-level data not available</em></p>';
            }
            
          } catch (error) {
            console.error('Camera OCR failed:', error);
            updateLog(`Camera OCR failed: ${error.message}`);
          }
        }
        
        // Event listeners for camera buttons
        startButton.addEventListener('click', startCamera);
        stopButton.addEventListener('click', stopCamera);
        ocrButton.addEventListener('click', performOCROnCamera);
        
        // Initially hide the stop button
        stopButton.style.display = 'none';
    </script>

</html>